{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --ckpt_dir CKPT_DIR\n",
      "ipykernel_launcher.py: error: the following arguments are required: --ckpt_dir\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/argparse.py:1943\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args2\u001b[0;34m(self, args, namespace, intermixed)\u001b[0m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1943\u001b[0m     namespace, args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintermixed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/argparse.py:2230\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[0;34m(self, arg_strings, namespace, intermixed)\u001b[0m\n\u001b[1;32m   2229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_actions:\n\u001b[0;32m-> 2230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ArgumentError(\u001b[38;5;28;01mNone\u001b[39;00m, _(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe following arguments are required: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   2231\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(required_actions))\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;66;03m# make sure all required groups had one option present\u001b[39;00m\n",
      "\u001b[0;31mArgumentError\u001b[0m: the following arguments are required: --ckpt_dir",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--ckpt_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m, required\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m---> 17\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m args\u001b[38;5;241m.\u001b[39mckpt_dir\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/argparse.py:1904\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1903\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1904\u001b[0m     args, argv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argv:\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/argparse.py:1914\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_known_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_known_args2\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintermixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/argparse.py:1945\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args2\u001b[0;34m(self, args, namespace, intermixed)\u001b[0m\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 1945\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/argparse.py:2650\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2649\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprog\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: message}\n\u001b[0;32m-> 2650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[38;5;124;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/argparse.py:2637\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_message(message, _sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 2637\u001b[0m \u001b[43m_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2095\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2093\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2094\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2095\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2099\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   2100\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   2101\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/IPython/core/ultratb.py:696\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/IPython/core/ultratb.py:559\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    556\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    557\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    558\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 559\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    563\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/IPython/core/ultratb.py:1396\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/IPython/core/ultratb.py:1287\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1284\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/IPython/core/ultratb.py:1140\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1133\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1138\u001b[0m ):\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1140\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/IPython/core/ultratb.py:1030\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1028\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1029\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1033\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1034\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/IPython/core/ultratb.py:1098\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "#  You can install and import any other libraries if needed\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--ckpt_dir\", type=str, required=True) \n",
    "\n",
    "args = parser.parse_args()\n",
    "checkpoint_dir = Path(\"checkpoints\") / args.ckpt_dir\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Chinese punctuations will be tokenized as [UNK], so we replace them with English ones\n",
    "token_replacement = [\n",
    "    [\"：\" , \":\"],\n",
    "    [\"，\" , \",\"],\n",
    "    [\"“\" , \"\\\"\"],\n",
    "    [\"”\" , \"\\\"\"],\n",
    "    [\"？\" , \"?\"],\n",
    "    [\"……\" , \"...\"],\n",
    "    [\"！\" , \"!\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\", cache_dir=\"./cache/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence_pair_id': 42, 'premise': 'Two people are kickboxing and spectators are not watching', 'hypothesis': 'Two people are kickboxing and spectators are watching', 'relatedness_score': 3.4000000953674316, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 88, 'premise': 'There is no biker jumping in the air', 'hypothesis': 'A lone biker is jumping in the air', 'relatedness_score': 4.199999809265137, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 90, 'premise': 'A man is jumping into an empty pool', 'hypothesis': 'A man is jumping into a full pool', 'relatedness_score': 3.0, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 122, 'premise': 'Five kids are standing close together and one kid has a gun', 'hypothesis': 'Five kids are standing close together and none of the kids has a gun', 'relatedness_score': 3.700000047683716, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 141, 'premise': 'A group of friends are riding the current in a raft', 'hypothesis': 'A group is not riding the current in a raft', 'relatedness_score': 3.700000047683716, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 150, 'premise': 'A deer is jumping over a fence', 'hypothesis': \"A deer isn't jumping over the fence\", 'relatedness_score': 3.9000000953674316, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 161, 'premise': 'Several people are in front of a colorful building', 'hypothesis': 'Nobody is in front of the colorful building', 'relatedness_score': 3.5, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 192, 'premise': 'A motorcycle rider is standing up on the seat of a white motorcycle', 'hypothesis': 'No motorcycle rider is standing up on the seat of a motorcycle', 'relatedness_score': 3.799999952316284, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 194, 'premise': 'Nobody is on a motorcycle and is standing on the seat', 'hypothesis': 'Someone is on a black and white motorcycle and is standing on the seat', 'relatedness_score': 3.700000047683716, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 201, 'premise': 'There is no motorcyclist riding a motorbike along a roadway', 'hypothesis': 'A motorcyclist is riding a motorbike along a roadway', 'relatedness_score': 3.700000047683716, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 232, 'premise': 'Three Asian kids are dancing and a man is looking', 'hypothesis': 'Three Asian kids are dancing and there is no man looking', 'relatedness_score': 3.9000000953674316, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 254, 'premise': 'A hiker is on top of the mountain and is dancing', 'hypothesis': 'There is no hiker dancing on top of the mountain', 'relatedness_score': 3.200000047683716, 'entailment_judgment': 2}\n",
      "{'sentence_pair_id': 256, 'premise': 'There is no man on a rock high above some trees standing in a strange position', 'hypothesis': 'A man is on a rock high above some trees and is standing in a strange position', 'relatedness_score': 4.300000190734863, 'entailment_judgment': 2}\n"
     ]
    }
   ],
   "source": [
    "class SemevalDataset(Dataset):\n",
    "    def __init__(self, split=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        assert split in [\"train\", \"validation\", \"test\"]\n",
    "        self.data = load_dataset(\n",
    "            \"SemEvalWorkshop/sem_eval_2014_task_1\",  # <-- THIS IS THE FIX\n",
    "            trust_remote_code=True, split=split, cache_dir=\"./cache/\"\n",
    "        ).to_list()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        d = self.data[index]\n",
    "        # Replace Chinese punctuations with English ones\n",
    "        for k in [\"premise\", \"hypothesis\"]:\n",
    "            for tok in token_replacement:\n",
    "                d[k] = d[k].replace(tok[0], tok[1])\n",
    "        return d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "data_sample = SemevalDataset(split=\"train\").data[:100]\n",
    "# print(f\"Dataset example: \\n{data_sample[0]} \\n{data_sample[1]} \\n{data_sample[2]}\")\n",
    "# print(f\"example: {data_sample}\")\n",
    "for ds in data_sample:\n",
    "    if ds['entailment_judgment'] == 2:\n",
    "        print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "# You can modify these values if needed\n",
    "lr = 1e-4 # train from scratch 先試試看比較大的\n",
    "weight_decay=0.01 # train from scratch 先試比較大\n",
    "epochs = 50\n",
    "train_batch_size = 8\n",
    "validation_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO1: Create batched data for DataLoader\n",
    "# `collate_fn` is a function that defines how the data batch should be packed.\n",
    "# This function will be called in the DataLoader to pack the data batch.\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # TODO1-1: Implement the collate_fn function\n",
    "    # Write your code here\n",
    "    # The input parameter is a data batch (tuple), and this function packs it into tensors.\n",
    "    # Use tokenizer to pack tokenize and pack the data and its corresponding labels.\n",
    "    # Return the data batch and labels for each sub-task.\n",
    "    premise = []\n",
    "    hypothesis = []\n",
    "    relatedness_score = []\n",
    "    entail_judge = []\n",
    "    for data in batch:\n",
    "        premise.append(data[\"premise\"])\n",
    "        hypothesis.append(data[\"hypothesis\"])\n",
    "        relatedness_score.append(data[\"relatedness_score\"])\n",
    "        entail_judge.append(data[\"entailment_judgment\"])\n",
    "    input_batch = tokenizer(premise, \n",
    "                            hypothesis,\n",
    "                            padding=True,\n",
    "                            truncation=True,\n",
    "                            return_tensors=\"pt\",\n",
    "                            max_length=512 \n",
    "                            )\n",
    "    input_batch[\"relatedness_score\"] = torch.tensor(relatedness_score, dtype=torch.float)\n",
    "    input_batch[\"entailment_judgment\"] = torch.tensor(entail_judge, dtype=torch.long)\n",
    "    \n",
    "    return input_batch\n",
    "\n",
    "# TODO1-2: Define your DataLoader\n",
    "train_dataset = SemevalDataset(split=\"train\")\n",
    "val_dataset = SemevalDataset(split=\"validation\")\n",
    "test_dataset = SemevalDataset(split=\"test\")\n",
    "dl_train = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "dl_validation = DataLoader(val_dataset, batch_size=validation_batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "dl_test = DataLoader(test_dataset, batch_size=validation_batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO2: Construct your model\n",
    "class MultiLabelModel(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # config = BertConfig.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "        self.bert = BertModel.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "        self.hidden_layers = self.bert.config.hidden_size\n",
    "        \n",
    "        self.classification_head = torch.nn.Linear(self.hidden_layers, 3)\n",
    "        self.regression_head = torch.nn.Linear(self.hidden_layers, 1)\n",
    "        \n",
    "        # Write your code here\n",
    "        # Define what modules you will use in the model\n",
    "        # Please use \"google-bert/bert-base-uncased\" model (https://huggingface.co/google-bert/bert-base-uncased)\n",
    "        # Besides the base model, you may design additional architectures by incorporating linear layers, activation functions, or other neural components.\n",
    "        # Remark: The use of any additional pretrained language models is not permitted.\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, **kwargs):\n",
    "        # Write your code here\n",
    "        x = self.bert(input_ids, attention_mask, token_type_ids)\n",
    "        cls_token = x.pooler_output\n",
    "        \n",
    "        classification_logits = self.classification_head(cls_token)\n",
    "        regression_score = self.regression_head(cls_token)\n",
    "        return classification_logits, regression_score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO3: Define your optimizer and loss function\n",
    "\n",
    "model = MultiLabelModel().to(device)\n",
    "# TODO3-1: Define your Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# scheduler\n",
    "num_training_steps = len(dl_train)\n",
    "num_warmup_steps = int(0.1 * num_training_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=num_training_steps, num_training_steps=num_training_steps)\n",
    "# TODO3-2: Define your loss functions (you should have two)\n",
    "# Write your code here\n",
    "loss_classification = torch.nn.CrossEntropyLoss()\n",
    "loss_regression = torch.nn.MSELoss()\n",
    "regression_weight = 2\n",
    "# scoring functions\n",
    "psr = load(\"pearsonr\")\n",
    "acc = load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch [1/3]:   0%|          | 0/563 [00:00<?, ?it/s]/home/cvlab123/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Training epoch [1/3]:  81%|████████  | 454/563 [00:28<00:06, 15.81it/s, loss=1.99] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     total_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 23\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m})\n\u001b[1;32m     26\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(dl_validation)\n\u001b[1;32m     27\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation epoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score = 0.0\n",
    "for ep in range(epochs):\n",
    "    pbar = tqdm(dl_train)\n",
    "    pbar.set_description(f\"Training epoch [{ep+1}/{epochs}]\")\n",
    "    model.train()\n",
    "    # TODO4: Write the training loop\n",
    "    # Write your code here\n",
    "    # train your model\n",
    "    for batch in pbar:\n",
    "        device_batch = {k:v.to(device) for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "        classification_logits, regression_score = model.forward(**device_batch)\n",
    "        label_reg = device_batch[\"relatedness_score\"]\n",
    "        label_cls = device_batch[\"entailment_judgment\"]\n",
    "\n",
    "        loss_cls = loss_classification(classification_logits, label_cls)\n",
    "        loss_reg = loss_regression(regression_score, label_reg)\n",
    "        \n",
    "        total_loss = loss_cls + loss_reg * regression_weight\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        pbar.set_postfix({'loss': total_loss.item()})\n",
    "\n",
    "\n",
    "    pbar = tqdm(dl_validation)\n",
    "    pbar.set_description(f\"Validation epoch [{ep+1}/{epochs}]\")\n",
    "    model.eval()\n",
    "    # TODO5: Write the evaluation loop\n",
    "    # Write your code here\n",
    "    # Evaluate your model\n",
    "    # Output all the evaluation scores (PearsonCorr, Accuracy)\n",
    "    all_preds_cls = []\n",
    "    all_labels_cls = []\n",
    "    all_preds_reg = []\n",
    "    all_labels_reg = []\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            device_batch = {k:v.to(device) for k, v in batch.items()}\n",
    "            classification_logits, regression_score = model.forward(**device_batch)\n",
    "            label_cls = device_batch[\"entailment_judgment\"]\n",
    "            label_reg = device_batch[\"relatedness_score\"]\n",
    "            preds_cls = torch.argmax(classification_logits, dim=1)\n",
    "            \n",
    "            all_preds_cls.append(preds_cls.cpu())\n",
    "            all_labels_cls.append(label_cls.cpu())\n",
    "            all_preds_reg.append(regression_score.cpu())\n",
    "            all_labels_reg.append(label_reg.cpu())\n",
    "        \n",
    "    all_preds_cls = torch.cat(all_preds_cls)\n",
    "    all_labels_cls = torch.cat(all_labels_cls)\n",
    "    all_preds_reg = torch.cat(all_preds_reg).squeeze() # Squeeze to 1D\n",
    "    all_labels_reg = torch.cat(all_labels_reg)\n",
    "\n",
    "    accuracy = acc.compute(predictions=all_preds_cls, references=all_labels_cls)\n",
    "    pearson_corr = psr.compute(predictions=all_preds_reg, references=all_labels_reg)\n",
    "    accuracy_value = accuracy['accuracy']\n",
    "    pearson_value = pearson_corr['pearsonr']\n",
    "            # print(f\"F1 Score: {f1.compute()}\")\n",
    "    print(f\"Epoch {ep}: validation accuracy: {accuracy_value}, pearson_value: {pearson_value} \")\n",
    "        \n",
    "    if pearson_value + accuracy_value > best_score:\n",
    "        best_score = pearson_value + accuracy_value\n",
    "        torch.save(model.state_dict(), f'{checkpoint_dir}/best_model.ckpt')\n",
    "        print(f\"New best score: {best_score:.4f}. Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = MultiLabelModel().to(device)\n",
    "model.load_state_dict(torch.load(f\"./saved_models/best_model.ckpt\", weights_only=True))\n",
    "\n",
    "# Test Loop\n",
    "pbar = tqdm(dl_test, desc=\"Test\")\n",
    "model.eval()\n",
    "\n",
    "# TODO6: Write the test loop\n",
    "# Write your code here\n",
    "# We have loaded the best model with the highest evaluation score for you\n",
    "# Please implement the test loop to evaluate the model on the test dataset\n",
    "# We will have 10% of the total score for the test accuracy and pearson correlation\n",
    "all_preds_cls = []\n",
    "all_labels_cls = []\n",
    "all_preds_reg = []\n",
    "all_labels_reg = []\n",
    "with torch.no_grad():\n",
    "    for batch in pbar:\n",
    "        device_batch = {k:v.to(device) for k, v in batch.items()}\n",
    "        classification_logits, regression_score = model.forward(**device_batch)\n",
    "        label_cls = device_batch[\"entailment_judgment\"]\n",
    "        label_reg = device_batch[\"relatedness_score\"]\n",
    "        preds_cls = torch.argmax(classification_logits, dim=1)\n",
    "        \n",
    "        all_preds_cls.append(preds_cls.cpu())\n",
    "        all_labels_cls.append(label_cls.cpu())\n",
    "        all_preds_reg.append(regression_score.cpu())\n",
    "        all_labels_reg.append(label_reg.cpu())\n",
    "    \n",
    "all_preds_cls = torch.cat(all_preds_cls)\n",
    "all_labels_cls = torch.cat(all_labels_cls)\n",
    "all_preds_reg = torch.cat(all_preds_reg).squeeze() # Squeeze to 1D\n",
    "all_labels_reg = torch.cat(all_labels_reg)\n",
    "\n",
    "accuracy = acc.compute(predictions=all_preds_cls, references=all_labels_cls)\n",
    "pearson_corr = psr.compute(predictions=all_preds_reg, references=all_labels_reg)\n",
    "\n",
    "print(f\"test accuracy: {accuracy}\")\n",
    "print(f\"test pearson_corr: {pearson_corr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nthu_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
