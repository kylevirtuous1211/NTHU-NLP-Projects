{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-arithmetic\n",
    "\n",
    "## Dataset\n",
    "- [Arithmetic dataset](https://drive.google.com/file/d/1cMuL3hF9jefka9RyF4gEBIGGeFGZYHE-/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install seaborn\n",
    "# ! pip install opencc\n",
    "# ! pip install -U scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.utils.rnn\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import opencc\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14*(43+20)=</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(6+1)*5=</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13+32+29=</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31*(3-11)=</td>\n",
       "      <td>-248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24*49+1=</td>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           src   tgt\n",
       "0  14*(43+20)=   882\n",
       "1     (6+1)*5=    35\n",
       "2    13+32+29=    74\n",
       "3   31*(3-11)=  -248\n",
       "4     24*49+1=  1177"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_path, 'arithmetic_train.csv'))\n",
    "df_eval = pd.read_csv(os.path.join(data_path, 'arithmetic_eval.csv'))\n",
    "df_train.head()\n",
    "# df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the input data to string\n",
    "df_train['tgt'] = df_train['tgt'].apply(str)\n",
    "df_train['full_sequence'] = df_train['src'] + df_train['tgt']\n",
    "df_train['input_text'] = df_train['full_sequence'].apply(lambda s: s[:-1])\n",
    "df_train['target_text'] = df_train['full_sequence'].apply(lambda s: s[1:])\n",
    "\n",
    "\n",
    "# testing set\n",
    "df_eval['tgt'] = df_eval['tgt'].apply(lambda x: str(x))\n",
    "df_eval['full_answer'] = df_eval['src'] + df_eval['tgt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>full_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48+43+34=</td>\n",
       "      <td>125</td>\n",
       "      <td>48+43+34=125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30-(48+13)=</td>\n",
       "      <td>-31</td>\n",
       "      <td>30-(48+13)=-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(21*31)+10=</td>\n",
       "      <td>661</td>\n",
       "      <td>(21*31)+10=661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-27-10=</td>\n",
       "      <td>-35</td>\n",
       "      <td>2-27-10=-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(15*20)+24=</td>\n",
       "      <td>324</td>\n",
       "      <td>(15*20)+24=324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           src  tgt     full_answer\n",
       "0    48+43+34=  125    48+43+34=125\n",
       "1  30-(48+13)=  -31  30-(48+13)=-31\n",
       "2  (21*31)+10=  661  (21*31)+10=661\n",
       "3     2-27-10=  -35     2-27-10=-35\n",
       "4  (15*20)+24=  324  (15*20)+24=324"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train.head()\n",
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dictionary\n",
    " - The model cannot perform calculations directly with plain text.\n",
    " - Convert all text (numbers/symbols) into numerical representations.\n",
    " - Special tokens\n",
    "    - '&lt;pad&gt;'\n",
    "        - Each sentence within a batch may have different lengths.\n",
    "        - The length is padded with '&lt;pad&gt;' to match the longest sentence in the batch.\n",
    "    - '&lt;eos&gt;'\n",
    "        - Specifies the end of the generated sequence.\n",
    "        - Without '&lt;eos&gt;', the model will not know when to stop generating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, '<eos>': 1, '1': 2, '4': 3, '*': 4, '(': 5, '3': 6, '+': 7, '2': 8, '0': 9, ')': 10, '=': 11, '8': 12, '6': 13, '5': 14, '9': 15, '7': 16, '-': 17}\n",
      "{0: '<pad>', 1: '<eos>', 2: '1', 3: '4', 4: '*', 5: '(', 6: '3', 7: '+', 8: '2', 9: '0', 10: ')', 11: '=', 12: '8', 13: '6', 14: '5', 15: '9', 16: '7', 17: '-'}\n",
      "Vocab size 18\n"
     ]
    }
   ],
   "source": [
    "char_to_id = {}\n",
    "id_to_char = {}\n",
    "\n",
    "# write your code here\n",
    "# Build a dictionary and give every token in the train dataset an id\n",
    "# The dictionary should contain <eos> and <pad>\n",
    "# char_to_id is to conver charactors to ids, while id_to_char is the opposite\n",
    "char_to_id['<pad>'] = 0\n",
    "char_to_id['<eos>'] = 1\n",
    "longest_src_sequence_length = 0\n",
    "id = 2\n",
    "for src_string in df_train['full_sequence']:\n",
    "    for c in src_string:\n",
    "        if (len(src_string) > longest_src_sequence_length):\n",
    "            longest_src_sequence_length = len(src_string)\n",
    "        if (not char_to_id.get(c)):\n",
    "            char_to_id[c] = id\n",
    "            id += 1\n",
    "            \n",
    "print(char_to_id)\n",
    "id_to_char = { v: k for k, v in char_to_id.items()}\n",
    "print(id_to_char)\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "print('Vocab size {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    " - The data is processed into the format required for the model's input and output. (End with \\<eos\\> token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>full_sequence</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>tgt_list</th>\n",
       "      <th>tgt_list_id</th>\n",
       "      <th>src_list</th>\n",
       "      <th>src_list_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14*(43+20)=</td>\n",
       "      <td>882</td>\n",
       "      <td>14*(43+20)=882</td>\n",
       "      <td>14*(43+20)=88</td>\n",
       "      <td>4*(43+20)=882</td>\n",
       "      <td>[4, *, (, 4, 3, +, 2, 0, ), =, 8, 8, 2, &lt;pad&gt;,...</td>\n",
       "      <td>[3, 4, 5, 3, 6, 7, 8, 9, 10, 11, 12, 12, 8, 0,...</td>\n",
       "      <td>[1, 4, *, (, 4, 3, +, 2, 0, ), =, 8, 8, &lt;pad&gt;,...</td>\n",
       "      <td>[2, 3, 4, 5, 3, 6, 7, 8, 9, 10, 11, 12, 12, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(6+1)*5=</td>\n",
       "      <td>35</td>\n",
       "      <td>(6+1)*5=35</td>\n",
       "      <td>(6+1)*5=3</td>\n",
       "      <td>6+1)*5=35</td>\n",
       "      <td>[6, +, 1, ), *, 5, =, 3, 5, &lt;pad&gt;, &lt;pad&gt;, &lt;pad...</td>\n",
       "      <td>[13, 7, 2, 10, 4, 14, 11, 6, 14, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[(, 6, +, 1, ), *, 5, =, 3, &lt;pad&gt;, &lt;pad&gt;, &lt;pad...</td>\n",
       "      <td>[5, 13, 7, 2, 10, 4, 14, 11, 6, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13+32+29=</td>\n",
       "      <td>74</td>\n",
       "      <td>13+32+29=74</td>\n",
       "      <td>13+32+29=7</td>\n",
       "      <td>3+32+29=74</td>\n",
       "      <td>[3, +, 3, 2, +, 2, 9, =, 7, 4, &lt;pad&gt;, &lt;pad&gt;, &lt;...</td>\n",
       "      <td>[6, 7, 6, 8, 7, 8, 15, 11, 16, 3, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 3, +, 3, 2, +, 2, 9, =, 7, &lt;pad&gt;, &lt;pad&gt;, &lt;...</td>\n",
       "      <td>[2, 6, 7, 6, 8, 7, 8, 15, 11, 16, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31*(3-11)=</td>\n",
       "      <td>-248</td>\n",
       "      <td>31*(3-11)=-248</td>\n",
       "      <td>31*(3-11)=-24</td>\n",
       "      <td>1*(3-11)=-248</td>\n",
       "      <td>[1, *, (, 3, -, 1, 1, ), =, -, 2, 4, 8, &lt;pad&gt;,...</td>\n",
       "      <td>[2, 4, 5, 6, 17, 2, 2, 10, 11, 17, 8, 3, 12, 0...</td>\n",
       "      <td>[3, 1, *, (, 3, -, 1, 1, ), =, -, 2, 4, &lt;pad&gt;,...</td>\n",
       "      <td>[6, 2, 4, 5, 6, 17, 2, 2, 10, 11, 17, 8, 3, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24*49+1=</td>\n",
       "      <td>1177</td>\n",
       "      <td>24*49+1=1177</td>\n",
       "      <td>24*49+1=117</td>\n",
       "      <td>4*49+1=1177</td>\n",
       "      <td>[4, *, 4, 9, +, 1, =, 1, 1, 7, 7, &lt;pad&gt;, &lt;pad&gt;...</td>\n",
       "      <td>[3, 4, 3, 15, 7, 2, 11, 2, 2, 16, 16, 0, 0, 0,...</td>\n",
       "      <td>[2, 4, *, 4, 9, +, 1, =, 1, 1, 7, &lt;pad&gt;, &lt;pad&gt;...</td>\n",
       "      <td>[8, 3, 4, 3, 15, 7, 2, 11, 2, 2, 16, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           src   tgt   full_sequence     input_text    target_text  \\\n",
       "0  14*(43+20)=   882  14*(43+20)=882  14*(43+20)=88  4*(43+20)=882   \n",
       "1     (6+1)*5=    35      (6+1)*5=35      (6+1)*5=3      6+1)*5=35   \n",
       "2    13+32+29=    74     13+32+29=74     13+32+29=7     3+32+29=74   \n",
       "3   31*(3-11)=  -248  31*(3-11)=-248  31*(3-11)=-24  1*(3-11)=-248   \n",
       "4     24*49+1=  1177    24*49+1=1177    24*49+1=117    4*49+1=1177   \n",
       "\n",
       "                                            tgt_list  \\\n",
       "0  [4, *, (, 4, 3, +, 2, 0, ), =, 8, 8, 2, <pad>,...   \n",
       "1  [6, +, 1, ), *, 5, =, 3, 5, <pad>, <pad>, <pad...   \n",
       "2  [3, +, 3, 2, +, 2, 9, =, 7, 4, <pad>, <pad>, <...   \n",
       "3  [1, *, (, 3, -, 1, 1, ), =, -, 2, 4, 8, <pad>,...   \n",
       "4  [4, *, 4, 9, +, 1, =, 1, 1, 7, 7, <pad>, <pad>...   \n",
       "\n",
       "                                         tgt_list_id  \\\n",
       "0  [3, 4, 5, 3, 6, 7, 8, 9, 10, 11, 12, 12, 8, 0,...   \n",
       "1  [13, 7, 2, 10, 4, 14, 11, 6, 14, 0, 0, 0, 0, 0...   \n",
       "2  [6, 7, 6, 8, 7, 8, 15, 11, 16, 3, 0, 0, 0, 0, ...   \n",
       "3  [2, 4, 5, 6, 17, 2, 2, 10, 11, 17, 8, 3, 12, 0...   \n",
       "4  [3, 4, 3, 15, 7, 2, 11, 2, 2, 16, 16, 0, 0, 0,...   \n",
       "\n",
       "                                            src_list  \\\n",
       "0  [1, 4, *, (, 4, 3, +, 2, 0, ), =, 8, 8, <pad>,...   \n",
       "1  [(, 6, +, 1, ), *, 5, =, 3, <pad>, <pad>, <pad...   \n",
       "2  [1, 3, +, 3, 2, +, 2, 9, =, 7, <pad>, <pad>, <...   \n",
       "3  [3, 1, *, (, 3, -, 1, 1, ), =, -, 2, 4, <pad>,...   \n",
       "4  [2, 4, *, 4, 9, +, 1, =, 1, 1, 7, <pad>, <pad>...   \n",
       "\n",
       "                                         src_list_id  \n",
       "0  [2, 3, 4, 5, 3, 6, 7, 8, 9, 10, 11, 12, 12, 0,...  \n",
       "1  [5, 13, 7, 2, 10, 4, 14, 11, 6, 0, 0, 0, 0, 0,...  \n",
       "2  [2, 6, 7, 6, 8, 7, 8, 15, 11, 16, 0, 0, 0, 0, ...  \n",
       "3  [6, 2, 4, 5, 6, 17, 2, 2, 10, 11, 17, 8, 3, 0,...  \n",
       "4  [8, 3, 4, 3, 15, 7, 2, 11, 2, 2, 16, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "# add paddiing and eos char first\n",
    "\n",
    "def string_to_list(curr_string, max_length):\n",
    "    str_list = list(curr_string)\n",
    "    original_length = len(curr_string)\n",
    "    str_list += [\"<pad>\"] * (max_length - original_length) + [\"<eos>\"]\n",
    "    \n",
    "    return str_list\n",
    "\n",
    "def list_to_id(token_list):\n",
    "    return [char_to_id[token] for token in token_list]\n",
    "    \n",
    "df_train['tgt_list'] = df_train['target_text'].apply(lambda s: string_to_list(s, longest_src_sequence_length))\n",
    "df_train['tgt_list_id'] = df_train['tgt_list'].apply(lambda s : list_to_id(s))\n",
    "df_train['src_list'] = df_train['input_text'].apply(lambda s: string_to_list(s, longest_src_sequence_length))\n",
    "df_train['src_list_id'] = df_train['src_list'].apply(lambda s : list_to_id(s))\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(longest_src_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 4, 5, 6, 17, 2, 2, 10, 11, 17, 8, 3, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(df_train['src_list_id'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters\n",
    "\n",
    "|Hyperparameter|Meaning|Value|\n",
    "|-|-|-|\n",
    "|`batch_size`|Number of data samples in a single batch|64|\n",
    "|`epochs`|Total number of epochs to train|10|\n",
    "|`embed_dim`|Dimension of the word embeddings|256|\n",
    "|`hidden_dim`|Dimension of the hidden state in each timestep of the LSTM|256|\n",
    "|`lr`|Learning Rate|0.001|\n",
    "|`grad_clip`|To prevent gradient explosion in RNNs, restrict the gradient range|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 2\n",
    "EMBED_DIM = 8\n",
    "HIDDEN_DIM = 256\n",
    "LR = 0.001\n",
    "GRAD_CLIP = 1\n",
    "\n",
    "# nohup python -u training_script.py > b128_e2_em8_h256_lr0.001.log &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Batching\n",
    "- Use `torch.utils.data.Dataset` to create a data generation tool called  `dataset`.\n",
    "- The, use `torch.utils.data.DataLoader` to randomly sample from the `dataset` and group the samples into batches.\n",
    "\n",
    "- Example: 1+2-3=0\n",
    "    - Model input: 1 + 2 - 3 = 0\n",
    "    - Model output: / / / / / 0 &lt;eos&gt;  (the '/' can be replaced with &lt;pad&gt;)\n",
    "    - The key for the model's output is that the model does not need to predict the next character of the previous part. What matters is that once the model sees '=', it should start generating the answer, which is '0'. After generating the answer, it should also generate&lt;eos&gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def __len__(self):\n",
    "        # return the amount of data\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Extract the input data x and the ground truth y from the data\n",
    "        x = self.dataframe['src_list_id'].iloc[index]\n",
    "        y = self.dataframe['tgt_list_id'].iloc[index]\n",
    "        return x, y\n",
    "\n",
    "# collate function, used to build dataloader\n",
    "def collate_fn(batch):\n",
    "    batch_x = [torch.tensor(data[0]) for data in batch]\n",
    "    batch_y = [torch.tensor(data[1]) for data in batch]\n",
    "    batch_x_lens = torch.LongTensor([len(x) for x in batch_x])\n",
    "    batch_y_lens = torch.LongTensor([len(y) for y in batch_y])\n",
    "    \n",
    "    # Pad the input sequence\n",
    "    pad_batch_x = torch.nn.utils.rnn.pad_sequence(batch_x,\n",
    "                                                  batch_first=True,\n",
    "                                                  padding_value=char_to_id['<pad>'])\n",
    "    \n",
    "    pad_batch_y = torch.nn.utils.rnn.pad_sequence(batch_y,\n",
    "                                                  batch_first=True,\n",
    "                                                  padding_value=char_to_id['<pad>'])\n",
    "    \n",
    "    return pad_batch_x, pad_batch_y, batch_x_lens, batch_y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset(df_train)\n",
    "ds_test = Dataset(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataloader of train set and eval set, collate_fn is the collate function\n",
    "dl_train = torch.utils.data.DataLoader(\n",
    "    ds_train, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True\n",
    ")\n",
    "dl_test = torch.utils.data.DataLoader(\n",
    "    ds_test, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design\n",
    "\n",
    "## Execution Flow\n",
    "1. Convert all characters in the sentence into embeddings.\n",
    "2. Pass the embeddings through an LSTM sequentially.\n",
    "3. The output of the LSTM is passed into another LSTM, and additional layers can be added.\n",
    "4. The output from all time steps of the final LSTM is passed through a Fully Connected layer.\n",
    "5. The character corresponding to the maximum value across all output dimensions is selected as the next character.\n",
    "\n",
    "## Loss Function\n",
    "Since this is a classification task, Cross Entropy is used as the loss function.\n",
    "\n",
    "## Gradient Update\n",
    "Adam algorithm is used for gradient updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(CharRNN, self).__init__()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size,\n",
    "                                            embedding_dim=embed_dim,\n",
    "                                            padding_idx=char_to_id['<pad>'])\n",
    "        \n",
    "        self.rnn_layer1 = torch.nn.LSTM(input_size=embed_dim,\n",
    "                                        hidden_size=hidden_dim,\n",
    "                                        batch_first=True)\n",
    "        \n",
    "        self.rnn_layer2 = torch.nn.LSTM(input_size=hidden_dim,\n",
    "                                        hidden_size=hidden_dim,\n",
    "                                        batch_first=True)\n",
    "        \n",
    "        self.linear = torch.nn.Sequential(torch.nn.Linear(in_features=hidden_dim,\n",
    "                                                          out_features=hidden_dim),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.Linear(in_features=hidden_dim,\n",
    "                                                          out_features=vocab_size))\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_lens):\n",
    "        return self.encoder(batch_x, batch_x_lens)\n",
    "    \n",
    "    # The forward pass of the model\n",
    "    def encoder(self, batch_x, batch_x_lens):\n",
    "        batch_x = self.embedding(batch_x)\n",
    "        \n",
    "        batch_x = torch.nn.utils.rnn.pack_padded_sequence(batch_x,\n",
    "                                                          batch_x_lens,\n",
    "                                                          batch_first=True,\n",
    "                                                          enforce_sorted=False)\n",
    "        \n",
    "        batch_x, _ = self.rnn_layer1(batch_x)\n",
    "        batch_x, _ = self.rnn_layer2(batch_x)\n",
    "        \n",
    "        batch_x, _ = torch.nn.utils.rnn.pad_packed_sequence(batch_x,\n",
    "                                                            batch_first=True)\n",
    "        \n",
    "        batch_x = self.linear(batch_x)\n",
    "        \n",
    "        return batch_x\n",
    "    \n",
    "    def generator(self, start_char, max_len=200):\n",
    "        \n",
    "        char_list = [char_to_id[c] for c in start_char]\n",
    "        \n",
    "        self.eval()\n",
    "        \n",
    "        next_char = None\n",
    "        with torch.no_grad():\n",
    "            while len(char_list) < max_len: \n",
    "                # Write your code here \n",
    "                # Pack the char_list to tensor\n",
    "                # Input the tensor to the embedding layer, LSTM layers, linear respectively\n",
    "                input_tensor = torch.tensor(char_list, dtype=torch.long).unsqueeze(0)\n",
    "                input_tensor = input_tensor.to(next(self.parameters()).device)\n",
    "                \n",
    "                embedded = self.embedding(input_tensor)\n",
    "                rnn_out, _ = self.rnn_layer1(embedded)\n",
    "                rnn_out, _ = self.rnn_layer2(rnn_out)\n",
    "                \n",
    "                last_token_logit = self.linear(rnn_out[:, -1, :])\n",
    "                next_char_id = torch.argmax(last_token_logit, dim=1).item()\n",
    "                \n",
    "                if next_char_id == char_to_id['<eos>']:\n",
    "                    break\n",
    "                \n",
    "                char_list.append(next_char_id)\n",
    "            \n",
    "        return [id_to_char[ch_id] for ch_id in char_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "\n",
    "print(vocab_size)\n",
    "device = 'cuda'\n",
    "\n",
    "model = CharRNN(vocab_size,\n",
    "                EMBED_DIM,\n",
    "                HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_idx = char_to_id['<pad>']\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=padding_idx)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "1. The outer `for` loop controls the `epoch`\n",
    "    1. The inner `for` loop uses `data_loader` to retrieve batches.\n",
    "        1. Pass the batch to the `model` for training.\n",
    "        2. Compare the predicted results `batch_pred_y` with the true labels `batch_y` using Cross Entropy to calculate the loss `loss`\n",
    "        3. Use `loss.backward` to automatically compute the gradients.\n",
    "        4. Use `torch.nn.utils.clip_grad_value_` to limit the gradient values between `-grad_clip` &lt; and &lt; `grad_clip`.\n",
    "        5. Use `optimizer.step()` to update the model (backpropagation).\n",
    "2.  After every `1000` batches, output the current loss to monitor whether it is converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1:   0%|          | 0/2369250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1:   0%|          | 8081/2369250 [00:27<2:13:11, 295.45it/s, loss=1.44]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_value_(model\u001b[38;5;241m.\u001b[39mparameters(), GRAD_CLIP) \u001b[38;5;66;03m# gradient clipping\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Write your code here\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Optimize parameters in the model\u001b[39;00m\n\u001b[1;32m     28\u001b[0m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/torch/optim/optimizer.py:472\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    471\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 472\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# call optimizer step pre hooks\u001b[39;49;00m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_global_optimizer_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/torch/autograd/profiler.py:733\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/nthu_nlp/lib/python3.12/site-packages/torch/_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "i = 0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # The process bar\n",
    "    bar = tqdm(dl_train, desc=f\"Train epoch {epoch}\")\n",
    "    for batch_x, batch_y, batch_x_lens, batch_y_lens in bar:\n",
    "        # Write your code here\n",
    "        # Clear the gradient\n",
    "        optimizer.zero_grad()\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        batch_pred_y = model(batch_x, batch_x_lens)\n",
    "        \n",
    "        # Write your code here\n",
    "        # Input the prediction and ground truths to loss function\n",
    "        # Back propagation\n",
    "        loss = criterion(batch_pred_y.view(-1, vocab_size), batch_y.view(-1))\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), GRAD_CLIP) # gradient clipping\n",
    "\n",
    "        optimizer.step()\n",
    "        # Write your code here\n",
    "        # Optimize parameters in the model\n",
    "\n",
    "        i+=1\n",
    "        if i%50==0:\n",
    "            bar.set_postfix(loss = loss.item())\n",
    "    \n",
    "    # Evaluate your model\n",
    "    model.eval()\n",
    "    matched = 0\n",
    "    total = 0\n",
    "    bar_eval = tqdm(df_eval.iterrows(), desc=f\"Validation epoch {epoch}\")\n",
    "    for _, row in bar_eval:\n",
    "        batch_x = row['src']\n",
    "        batch_y = row['tgt']\n",
    "        \n",
    "        prediction = model.generator(batch_x)# An example of using generator: model.generator('1+1=')\n",
    "        \n",
    "        if prediction == batch_y:\n",
    "            matched += 1\n",
    "        total += 1\n",
    "        # Write your code here. Input the batch_x to the model and generate the predictions\n",
    "        # Write your code here.\n",
    "        # Check whether the prediction match the ground truths\n",
    "        # Compute exact match (EM) on the eval dataset\n",
    "        # EM = correct/total\n",
    "\n",
    "        \n",
    "    em_accuracy = matched / total if total > 0 else 0\n",
    "    print(f\"Validation Epoch {epoch} | Exact Match Accuracy: {em_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nthu_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
